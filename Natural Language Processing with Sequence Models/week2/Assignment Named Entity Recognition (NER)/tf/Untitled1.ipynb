{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31101440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# set random seeds to make this notebook easier to replicate\n",
    "tf.keras.utils.set_random_seed(33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eba136a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing load dataset with a small subset\n",
    "\n",
    "# display original kaggle data\n",
    "data = pd.read_csv(\"data/ner_dataset.csv\", encoding = \"ISO-8859-1\")\n",
    "train_sents = open('data/small/train/sentences.txt', 'r').readline()\n",
    "train_labels = open('data/small/train/labels.txt', 'r').readline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf7de82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        data = np.array([ line.strip() for line in file.readlines()])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "611a81c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = load_data('data/large/train/sentences.txt')\n",
    "train_labels = load_data('data/large/train/labels.txt')\n",
    "\n",
    "val_sentences = load_data('data/large/val/sentences.txt')\n",
    "val_labels = load_data('data/large/val/labels.txt')\n",
    "\n",
    "test_sentences = load_data('data/large/test/sentences.txt')\n",
    "test_labels = load_data('data/large/test/labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cf90ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorize sentences\n",
    "def get_vectorize_sentences(sentences):\n",
    "    \"\"\"\n",
    "    Input:array of sentences\n",
    "    Output: sentence vectorizer callable, vocab based on the data adapted\n",
    "    \"\"\"\n",
    "    \n",
    "    sentence_vectorizer = tf.keras.layers.TextVectorization(standardize=None)\n",
    "    sentence_vectorizer.adapt(sentences)\n",
    "    vocab = sentence_vectorizer.get_vocabulary()\n",
    "    \n",
    "    return sentence_vectorizer, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f98a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([ 296,  314,    1,   59,    1,    1, 4649])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorizer, test_vocab = get_vectorize_sentences(train_sentences[:1000])\n",
    "sentence = \"I like learning new NLP models !\"\n",
    "sentence_vectorized = test_vectorizer(sentence)\n",
    "sentence_vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c01f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_vectorizer, train_vocab = get_vectorize_sentences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f078825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label tag_map\n",
    "def tag_set_map(labels):\n",
    "    \n",
    "    tag_set=set()\n",
    "    for element in labels:\n",
    "        for i in element.split(' '):\n",
    "            tag_set.add(i)\n",
    "   \n",
    "    tag_set=sorted(tag_set)\n",
    "    tag_map={}\n",
    "    for i,tag in enumerate(tag_set):\n",
    "        tag_map[tag]=i\n",
    "    return tag_map, tag_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a10805",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_map, tag_set=tag_set_map(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e8eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label vectorizer and add padding\n",
    "\n",
    "def label_vectorizer(labels,tag_map=tag_map):\n",
    "    \n",
    "    label_ids=[]\n",
    "    element_id=[]\n",
    "    for element in labels:\n",
    "        for i in element.split(' '):\n",
    "            element_id.append(tag_map[i])\n",
    "        label_ids.append(element_id)\n",
    "    \n",
    "    # Pad the elements\n",
    "    label_ids = tf.keras.utils.pad_sequences(sequences=label_ids, padding='post', value=-1)\n",
    "    \n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aa1e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The party is divided over Britain 's participation in the Iraq conflict and the continued deployment of 8,500 British troops in that country .\n",
      "Labels: O O O O O B-gpe O O O O B-geo O O O O O O O B-gpe O O O O O\n",
      "Vectorized labels: [[16 16 16 16 16  3 16 16 16 16  2 16 16 16 16 16 16 16  3 16 16 16 16 16]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sentence: {train_sentences[5]}\")\n",
    "print(f\"Labels: {train_labels[5]}\")\n",
    "print(f\"Vectorized labels: {label_vectorizer([train_labels[5]], tag_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4e9f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the dataset\n",
    "\n",
    "def generate_dataset(sentences, labels, sentence_vectorizer, tag_map):\n",
    "    \n",
    "    \"\"\"\n",
    "    vectorize sentences\n",
    "    vectorize labels\n",
    "    combine sentences = labels\n",
    "    \"\"\"\n",
    "    \n",
    "    sentences = sentence_vectorizer(sentences)\n",
    "    labels = label_vectorizer(labels,tag_map)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sentences, labels))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbdd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = generate_dataset(train_sentences,train_labels,sentence_vectorizer, tag_map)\n",
    "test_dataset = generate_dataset(test_sentences,test_labels,sentence_vectorizer, tag_map)\n",
    "val_dataset = generate_dataset(val_sentences,val_labels,sentence_vectorizer, tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d84c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_tag = len(tag_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93f8dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(train_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12fa530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a model\n",
    "\n",
    "def NER(vocab_size,len_tag):\n",
    "    \n",
    "    \"\"\"\n",
    "    squence model\n",
    "    -emb\n",
    "    -lstm\n",
    "    -dense\n",
    "    -log softmax\n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential(name = 'sequential') \n",
    "    model.add(tf.keras.layers.Embedding(input_dim=vocab_size+1,output_dim=64,mask_zero=True))\n",
    "    model.add(tf.keras.layers.LSTM(units=128, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Dense(units=len_tag,activation='ReLU'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c7d7a51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m NER(\u001b[43mvocab_size\u001b[49m,len_tag)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "NER(vocab_size,len_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#masked loss\n",
    "\n",
    "def masked_loss(y_true,y_pred):\n",
    "    \n",
    "    loss_fun = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,ignore_class=-1)\n",
    "    return loss_fun(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3427c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = [0,1,2,0]\n",
    "predicted_logits = [[0.1,0.6,0.3] , [0.2,0.7,0.1], [0.1, 0.5,0.4], [0.4,0.4,0.2]]\n",
    "print(masked_loss(true_labels, predicted_logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a3e012",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (550523838.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#masked accuracy\n",
    "\n",
    "def masked_accuracy(y_true,y_pred):\n",
    "    \"\"\"\n",
    "    total y_true==y_pred except the padding/total y_true without the padding\n",
    "    \"\"\"\n",
    "    \n",
    "    np.equal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccca799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
